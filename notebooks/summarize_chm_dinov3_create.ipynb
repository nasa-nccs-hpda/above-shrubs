{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bdff1b4-1337-451c-aff0-aa606d8ece05",
   "metadata": {},
   "source": [
    "# Summarize CHM results from DINOv3 - create area summary for height bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df9c6b72-d325-4c68-908b-5f6765120656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2acf33fa-7b98-4fa0-b2ea-c309f2f50a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_height_class_areas(filepath, height_bins=None):\n",
    "    \"\"\"\n",
    "    Compute area for each height class in a single raster.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    filepath : str\n",
    "        Path to GeoTIFF\n",
    "    height_bins : list of tuples\n",
    "        Height ranges, e.g., [(0.25, 5), (5, 10), (10, 20)]\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict with areas per height class\n",
    "    \"\"\"\n",
    "    if height_bins is None:\n",
    "        height_bins = [(0,0.25), (0.25, 5), (5, 10), (10, 20), (20, 50)]\n",
    "    \n",
    "    try:\n",
    "        with rasterio.open(filepath) as src:\n",
    "            data = src.read(1)\n",
    "            transform = src.transform\n",
    "            \n",
    "            # Get pixel area in mÂ²\n",
    "            pixel_width = abs(transform[0])   # meters\n",
    "            pixel_height = abs(transform[4])  # meters\n",
    "            pixel_area_m2 = pixel_width * pixel_height\n",
    "            pixel_area_km2 = pixel_area_m2 / 1e6\n",
    "            \n",
    "            # Mask nodata\n",
    "            if src.nodata is not None:\n",
    "                valid_mask = data != src.nodata\n",
    "            else:\n",
    "                valid_mask = np.ones_like(data, dtype=bool)\n",
    "            \n",
    "            # Calculate area for each height class\n",
    "            results = {'file': filepath}\n",
    "            \n",
    "            for min_h, max_h in height_bins:\n",
    "                class_name = f'{min_h}-{max_h}m'\n",
    "                mask = (data >= min_h) & (data < max_h) & valid_mask\n",
    "                n_pixels = np.sum(mask)\n",
    "                area_km2 = n_pixels * pixel_area_km2\n",
    "                results[f'area_{class_name}'] = area_km2\n",
    "                results[f'n_pixels_{class_name}'] = n_pixels\n",
    "            \n",
    "            # IMPORTANT: Total valid area for this file\n",
    "            results['total_valid_area_km2'] = np.sum(valid_mask) * pixel_area_km2\n",
    "            results['n_valid_pixels'] = np.sum(valid_mask)\n",
    "            \n",
    "            return results\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filepath}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dffa729-adf7-4675-a54e-1323ff8973d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2598a1d3-0d16-4ad5-bbff-6277288fd4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1288 files from July and August (out of 3219 total)\n"
     ]
    }
   ],
   "source": [
    "files_chm = glob.glob('/explore/nobackup/projects/above/misc/ABoVE_Shrubs/chm/2026_chm/4.3.2.5/002m/*-sr-02m.chm.tif')\n",
    "# Filter for July (07) and August (08) in YYYYMMDD format\n",
    "# Pattern matches: WV02_20230715_*, WV03_20190828_*, etc.\n",
    "files_chm_jujlyaug = [f for f in files_chm if re.search(r'_\\d{4}(07|08)\\d{2}_', f)]\n",
    "\n",
    "print(f\"Found {len(files_chm_jujlyaug)} files from July and August (out of {len(files_chm)} total)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8407f4ef-3c3e-4da2-8d38-a9ea02e092ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_chm_jujlyaug = files_chm_jujlyaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edb7b53e-968c-4531-920f-bd379642c6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "height_bins = [(0,0.25), (0.25, 1), (1,2), (2,3), (3, 5), (5, 10), (10, 20), (20, 50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1514969-1022-4044-9056-bf9e5ec4ce38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=35)]: Using backend LokyBackend with 35 concurrent workers.\n",
      "[Parallel(n_jobs=35)]: Done   2 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=35)]: Done  15 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=35)]: Done  28 tasks      | elapsed:   22.1s\n",
      "/panfs/ccds02/app/modules/jupyter/ilab/tensorflow-kernel/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=35)]: Done  43 tasks      | elapsed:   25.8s\n",
      "[Parallel(n_jobs=35)]: Done  58 tasks      | elapsed:   32.6s\n",
      "[Parallel(n_jobs=35)]: Done  75 tasks      | elapsed:   39.1s\n",
      "[Parallel(n_jobs=35)]: Done  92 tasks      | elapsed:   48.5s\n",
      "[Parallel(n_jobs=35)]: Done 111 tasks      | elapsed:   54.9s\n",
      "[Parallel(n_jobs=35)]: Done 130 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=35)]: Done 151 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=35)]: Done 172 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=35)]: Done 195 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=35)]: Done 218 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=35)]: Done 243 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=35)]: Done 268 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=35)]: Done 295 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=35)]: Done 322 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=35)]: Done 351 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=35)]: Done 380 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=35)]: Done 411 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=35)]: Done 442 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=35)]: Done 475 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=35)]: Done 508 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=35)]: Done 543 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=35)]: Done 578 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=35)]: Done 615 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=35)]: Done 652 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=35)]: Done 691 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=35)]: Done 730 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=35)]: Done 771 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=35)]: Done 812 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=35)]: Done 855 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=35)]: Done 898 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=35)]: Done 943 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=35)]: Done 988 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=35)]: Done 1035 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=35)]: Done 1082 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=35)]: Done 1131 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=35)]: Done 1180 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=35)]: Done 1288 out of 1288 | elapsed:  8.3min finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Much more Jupyter-friendly\n",
    "results = Parallel(n_jobs=35, verbose=10)(\n",
    "    delayed(compute_height_class_areas)(f, height_bins) \n",
    "    for f in files_chm_jujlyaug\n",
    ")\n",
    "\n",
    "area_stats_df = pd.DataFrame([r for r in results if r is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b06c9f85-67dd-4bad-bf4b-d2da92864a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save detailed results\n",
    "area_stats_df.to_csv('/explore/nobackup/projects/above/misc/ABoVE_Shrubs/chm/2026_chm/4.3.2.5/chm_002m_height_class_areas_by_file.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ILAB Kernel",
   "language": "python",
   "name": "ilab-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
